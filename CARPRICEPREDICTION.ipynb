{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyMBlWuFH9NUAFYWem9V9g8c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2256haradityam/Projects/blob/main/CARPRICEPREDICTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4m3-2g621mK6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://github.com/2256haradityam/dataset/raw/refs/heads/main/breast-cancer_updated.csv')"
      ],
      "metadata": {
        "id": "mo5jHXYL2YWI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4tJ5fwpb2b7f",
        "outputId": "60d32cad-fef3-4ad7-a962-c476ce04fe36"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CLASS  SOT  INV  NC  DM  IR       ACI  MII  RNI  CSR       NIS  RI  \\\n",
              "0      0   34    2   0   3   0 -0.204639    0    0    0 -0.210591   0   \n",
              "1      0   24    2   0   2   0 -0.453878    0    0    0 -0.405141   0   \n",
              "2      0   24    2   0   2   0 -0.453878    0    0    0 -0.405141   0   \n",
              "3      0   19    2   0   2   0 -0.453878    0    0    0 -0.405141   0   \n",
              "4      0    4    2   0   2   0 -0.453878    0    0    0 -0.405141   0   \n",
              "\n",
              "        NTI      TPRI  NCM     TNRF  MRW       ATR       MTI  \n",
              "0 -0.325646 -0.133848    0 -0.47724    0 -0.519494 -0.456972  \n",
              "1 -0.492194 -0.450079    0 -0.47724    0 -0.624535 -0.555509  \n",
              "2 -0.492194 -0.450079    0 -0.47724    0 -0.624535 -0.555509  \n",
              "3 -0.575468 -0.508640    0 -0.47724    0 -0.309411 -0.417557  \n",
              "4 -0.825291 -0.684324    0 -0.47724    0 -2.025086 -0.752584  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a333ee7-4284-4265-8c13-2e5ba9e2287a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CLASS</th>\n",
              "      <th>SOT</th>\n",
              "      <th>INV</th>\n",
              "      <th>NC</th>\n",
              "      <th>DM</th>\n",
              "      <th>IR</th>\n",
              "      <th>ACI</th>\n",
              "      <th>MII</th>\n",
              "      <th>RNI</th>\n",
              "      <th>CSR</th>\n",
              "      <th>NIS</th>\n",
              "      <th>RI</th>\n",
              "      <th>NTI</th>\n",
              "      <th>TPRI</th>\n",
              "      <th>NCM</th>\n",
              "      <th>TNRF</th>\n",
              "      <th>MRW</th>\n",
              "      <th>ATR</th>\n",
              "      <th>MTI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.204639</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.210591</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.325646</td>\n",
              "      <td>-0.133848</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.47724</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.519494</td>\n",
              "      <td>-0.456972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.453878</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.405141</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.492194</td>\n",
              "      <td>-0.450079</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.47724</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.624535</td>\n",
              "      <td>-0.555509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.453878</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.405141</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.492194</td>\n",
              "      <td>-0.450079</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.47724</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.624535</td>\n",
              "      <td>-0.555509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.453878</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.405141</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.575468</td>\n",
              "      <td>-0.508640</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.47724</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.309411</td>\n",
              "      <td>-0.417557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.453878</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.405141</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.825291</td>\n",
              "      <td>-0.684324</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.47724</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.025086</td>\n",
              "      <td>-0.752584</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a333ee7-4284-4265-8c13-2e5ba9e2287a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a333ee7-4284-4265-8c13-2e5ba9e2287a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a333ee7-4284-4265-8c13-2e5ba9e2287a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a0a0447a-c3ab-455b-b777-1612cb2eaf6e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a0a0447a-c3ab-455b-b777-1612cb2eaf6e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a0a0447a-c3ab-455b-b777-1612cb2eaf6e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 285,\n  \"fields\": [\n    {\n      \"column\": \"CLASS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SOT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 4,\n        \"max\": 50,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          50,\n          34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"INV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 2,\n        \"max\": 26,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ACI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0017590163110903,\n        \"min\": -0.7031174763123591,\n        \"max\": 6.026346429438392,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          -0.2046386684789701,\n          -0.4538780723956646\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MII\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RNI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 26,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          8,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CSR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NIS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0017590163110905,\n        \"min\": -0.599690627253844,\n        \"max\": 6.793194396262526,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -0.3078662184308294,\n          2.4158282639173065\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NTI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0017590163110903,\n        \"min\": -0.8252905240081804,\n        \"max\": 5.336995597901015,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          2.4890201199375763,\n          0.0407604985304093\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TPRI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0017590163110903,\n        \"min\": -0.7077479861484692,\n        \"max\": 5.0927382634107214,\n        \"num_unique_values\": 67,\n        \"samples\": [\n          0.7621379791613309,\n          -0.6199061953929035\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NCM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TNRF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0017590163110903,\n        \"min\": -0.4772396686687069,\n        \"max\": 3.2004250652876185,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          1.874054177631239,\n          2.5975292072619918\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MRW\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ATR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0017590163110903,\n        \"min\": -2.0951131625819195,\n        \"max\": 3.086924143408368,\n        \"num_unique_values\": 46,\n        \"samples\": [\n          -1.674947975609734,\n          -1.0447001951514558\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MTI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0017590163110903,\n        \"min\": -0.7525839987684065,\n        \"max\": 6.5786013321845465,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          -0.4569716870364326,\n          -0.3190192748948448\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_encode = [ 'SOT',  'INV', 'DM','RNI','CSR','MII','NCM','MRW']\n",
        "\n",
        "# Perform One-Hot Encoding and drop the original columns\n",
        "df_encoded = pd.get_dummies(df, columns=columns_to_encode)\n",
        "df_encoded = df_encoded.astype(int)"
      ],
      "metadata": {
        "id": "BPdWR0k62e-n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Rud4P79GI7BO",
        "outputId": "50cecb4f-a0a0-4155-808d-fa10a556dbbe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CLASS  NC  IR  ACI  NIS  RI  NTI  TPRI  TNRF  ATR  ...  MII_0  MII_1  \\\n",
              "0      0   0   0    0    0   0    0     0     0    0  ...      1      0   \n",
              "1      0   0   0    0    0   0    0     0     0    0  ...      1      0   \n",
              "2      0   0   0    0    0   0    0     0     0    0  ...      1      0   \n",
              "3      0   0   0    0    0   0    0     0     0    0  ...      1      0   \n",
              "4      0   0   0    0    0   0    0     0     0   -2  ...      1      0   \n",
              "\n",
              "   MII_2  MII_3  NCM_0  NCM_2  NCM_3  MRW_0  MRW_2  MRW_3  \n",
              "0      0      0      1      0      0      1      0      0  \n",
              "1      0      0      1      0      0      1      0      0  \n",
              "2      0      0      1      0      0      1      0      0  \n",
              "3      0      0      1      0      0      1      0      0  \n",
              "4      0      0      1      0      0      1      0      0  \n",
              "\n",
              "[5 rows x 53 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3bc9d6b9-d21e-4714-92bc-be144f6f7cd4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CLASS</th>\n",
              "      <th>NC</th>\n",
              "      <th>IR</th>\n",
              "      <th>ACI</th>\n",
              "      <th>NIS</th>\n",
              "      <th>RI</th>\n",
              "      <th>NTI</th>\n",
              "      <th>TPRI</th>\n",
              "      <th>TNRF</th>\n",
              "      <th>ATR</th>\n",
              "      <th>...</th>\n",
              "      <th>MII_0</th>\n",
              "      <th>MII_1</th>\n",
              "      <th>MII_2</th>\n",
              "      <th>MII_3</th>\n",
              "      <th>NCM_0</th>\n",
              "      <th>NCM_2</th>\n",
              "      <th>NCM_3</th>\n",
              "      <th>MRW_0</th>\n",
              "      <th>MRW_2</th>\n",
              "      <th>MRW_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 53 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bc9d6b9-d21e-4714-92bc-be144f6f7cd4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3bc9d6b9-d21e-4714-92bc-be144f6f7cd4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3bc9d6b9-d21e-4714-92bc-be144f6f7cd4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d5230975-4790-4bff-80ac-4c36fe50afe1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d5230975-4790-4bff-80ac-4c36fe50afe1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d5230975-4790-4bff-80ac-4c36fe50afe1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_encoded"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded.info()"
      ],
      "metadata": {
        "id": "KTmpSPFWHwxm",
        "outputId": "a9cbbf05-c3d3-440c-ca87-04f8c6e9a4f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 285 entries, 0 to 284\n",
            "Data columns (total 53 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   CLASS   285 non-null    int64\n",
            " 1   NC      285 non-null    int64\n",
            " 2   IR      285 non-null    int64\n",
            " 3   ACI     285 non-null    int64\n",
            " 4   NIS     285 non-null    int64\n",
            " 5   RI      285 non-null    int64\n",
            " 6   NTI     285 non-null    int64\n",
            " 7   TPRI    285 non-null    int64\n",
            " 8   TNRF    285 non-null    int64\n",
            " 9   ATR     285 non-null    int64\n",
            " 10  MTI     285 non-null    int64\n",
            " 11  SOT_4   285 non-null    int64\n",
            " 12  SOT_9   285 non-null    int64\n",
            " 13  SOT_14  285 non-null    int64\n",
            " 14  SOT_19  285 non-null    int64\n",
            " 15  SOT_24  285 non-null    int64\n",
            " 16  SOT_29  285 non-null    int64\n",
            " 17  SOT_34  285 non-null    int64\n",
            " 18  SOT_39  285 non-null    int64\n",
            " 19  SOT_44  285 non-null    int64\n",
            " 20  SOT_49  285 non-null    int64\n",
            " 21  SOT_50  285 non-null    int64\n",
            " 22  INV_2   285 non-null    int64\n",
            " 23  INV_5   285 non-null    int64\n",
            " 24  INV_8   285 non-null    int64\n",
            " 25  INV_11  285 non-null    int64\n",
            " 26  INV_14  285 non-null    int64\n",
            " 27  INV_17  285 non-null    int64\n",
            " 28  INV_26  285 non-null    int64\n",
            " 29  DM_1    285 non-null    int64\n",
            " 30  DM_2    285 non-null    int64\n",
            " 31  DM_3    285 non-null    int64\n",
            " 32  RNI_0   285 non-null    int64\n",
            " 33  RNI_2   285 non-null    int64\n",
            " 34  RNI_5   285 non-null    int64\n",
            " 35  RNI_8   285 non-null    int64\n",
            " 36  RNI_11  285 non-null    int64\n",
            " 37  RNI_14  285 non-null    int64\n",
            " 38  RNI_17  285 non-null    int64\n",
            " 39  RNI_26  285 non-null    int64\n",
            " 40  CSR_0   285 non-null    int64\n",
            " 41  CSR_2   285 non-null    int64\n",
            " 42  CSR_3   285 non-null    int64\n",
            " 43  MII_0   285 non-null    int64\n",
            " 44  MII_1   285 non-null    int64\n",
            " 45  MII_2   285 non-null    int64\n",
            " 46  MII_3   285 non-null    int64\n",
            " 47  NCM_0   285 non-null    int64\n",
            " 48  NCM_2   285 non-null    int64\n",
            " 49  NCM_3   285 non-null    int64\n",
            " 50  MRW_0   285 non-null    int64\n",
            " 51  MRW_2   285 non-null    int64\n",
            " 52  MRW_3   285 non-null    int64\n",
            "dtypes: int64(53)\n",
            "memory usage: 118.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming 'df_encoded' is your encoded DataFrame with the target column 'CLASS'\n",
        "target_column = 'CLASS'\n",
        "\n",
        "# Split into features and target\n",
        "X = df_encoded.drop(target_column, axis=1)\n",
        "y = df_encoded[target_column]\n",
        "\n",
        "# Duplicate data 10 times\n",
        "X_duplicated = pd.concat([X] * 3, ignore_index=True)\n",
        "y_duplicated = pd.concat([y] * 3, ignore_index=True)\n",
        "\n",
        "# Shuffle the duplicated data in a highly random order\n",
        "df_duplicated = pd.concat([X_duplicated, y_duplicated], axis=1).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split shuffled data back into features and target\n",
        "X_shuffled = df_duplicated.drop(target_column, axis=1)\n",
        "y_shuffled = df_duplicated[target_column]\n",
        "\n",
        "# Define K-Fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Classifier and parameter grid for brute-force optimization\n",
        "classifier = SVC()\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Brute force search using GridSearchCV with KFold cross-validation and train_test_split\n",
        "train_test_splits = [\n",
        "    0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14,\n",
        "    0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24,\n",
        "    0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34,\n",
        "    0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44,\n",
        "    0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n",
        "    0.55, 0.56, 0.57, 0.58, 0.59, 0.6\n",
        "]  # Different train-test split ratios\n",
        "\n",
        "best_models = {}\n",
        "for split_ratio in train_test_splits:\n",
        "    print(f\"\\nEvaluating with train_test_split ratio: {1 - split_ratio} train, {split_ratio} test\\n\")\n",
        "\n",
        "    # Split the shuffled data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=split_ratio, random_state=42)\n",
        "\n",
        "    print(f\"Training SVM with split {split_ratio}...\")\n",
        "\n",
        "    # Brute force with GridSearchCV and KFold\n",
        "    grid_search = GridSearchCV(classifier, param_grid, cv=kf, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Evaluate the best model on the test data\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"SVM Accuracy with split {split_ratio}: {accuracy}\")\n",
        "    print(f\"SVM Classification Report with split {split_ratio}:\\n\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Store the best model for each split\n",
        "    best_models[split_ratio] = best_model\n",
        "\n",
        "# After completing all splits, the best models will be stored in `best_models`\n"
      ],
      "metadata": {
        "id": "t7FR-EkgKQ5W",
        "outputId": "e2003845-8169-4447-9654-42c1da243169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating with train_test_split ratio: 0.95 train, 0.05 test\n",
            "\n",
            "Training SVM with split 0.05...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.05: 0.8604651162790697\n",
            "SVM Classification Report with split 0.05:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.96      0.88        24\n",
            "           1       0.93      0.74      0.82        19\n",
            "\n",
            "    accuracy                           0.86        43\n",
            "   macro avg       0.88      0.85      0.85        43\n",
            "weighted avg       0.87      0.86      0.86        43\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.94 train, 0.06 test\n",
            "\n",
            "Training SVM with split 0.06...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.06: 0.8653846153846154\n",
            "SVM Classification Report with split 0.06:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.94      0.90        32\n",
            "           1       0.88      0.75      0.81        20\n",
            "\n",
            "    accuracy                           0.87        52\n",
            "   macro avg       0.87      0.84      0.85        52\n",
            "weighted avg       0.87      0.87      0.86        52\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.9299999999999999 train, 0.07 test\n",
            "\n",
            "Training SVM with split 0.07...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.07: 0.8666666666666667\n",
            "SVM Classification Report with split 0.07:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90        37\n",
            "           1       0.89      0.74      0.81        23\n",
            "\n",
            "    accuracy                           0.87        60\n",
            "   macro avg       0.87      0.84      0.85        60\n",
            "weighted avg       0.87      0.87      0.86        60\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.92 train, 0.08 test\n",
            "\n",
            "Training SVM with split 0.08...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.08: 0.8695652173913043\n",
            "SVM Classification Report with split 0.08:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90        44\n",
            "           1       0.90      0.72      0.80        25\n",
            "\n",
            "    accuracy                           0.87        69\n",
            "   macro avg       0.88      0.84      0.85        69\n",
            "weighted avg       0.87      0.87      0.87        69\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.91 train, 0.09 test\n",
            "\n",
            "Training SVM with split 0.09...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.09: 0.8701298701298701\n",
            "SVM Classification Report with split 0.09:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90        47\n",
            "           1       0.92      0.73      0.81        30\n",
            "\n",
            "    accuracy                           0.87        77\n",
            "   macro avg       0.88      0.85      0.86        77\n",
            "weighted avg       0.88      0.87      0.87        77\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.9 train, 0.1 test\n",
            "\n",
            "Training SVM with split 0.1...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.1: 0.8837209302325582\n",
            "SVM Classification Report with split 0.1:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.92        56\n",
            "           1       0.92      0.73      0.81        30\n",
            "\n",
            "    accuracy                           0.88        86\n",
            "   macro avg       0.89      0.85      0.87        86\n",
            "weighted avg       0.89      0.88      0.88        86\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.89 train, 0.11 test\n",
            "\n",
            "Training SVM with split 0.11...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.11: 0.8947368421052632\n",
            "SVM Classification Report with split 0.11:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92        63\n",
            "           1       0.92      0.75      0.83        32\n",
            "\n",
            "    accuracy                           0.89        95\n",
            "   macro avg       0.90      0.86      0.88        95\n",
            "weighted avg       0.90      0.89      0.89        95\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.88 train, 0.12 test\n",
            "\n",
            "Training SVM with split 0.12...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.12: 0.9029126213592233\n",
            "SVM Classification Report with split 0.12:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.97      0.93        70\n",
            "           1       0.93      0.76      0.83        33\n",
            "\n",
            "    accuracy                           0.90       103\n",
            "   macro avg       0.91      0.86      0.88       103\n",
            "weighted avg       0.90      0.90      0.90       103\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.87 train, 0.13 test\n",
            "\n",
            "Training SVM with split 0.13...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.13: 0.9017857142857143\n",
            "SVM Classification Report with split 0.13:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.97      0.93        75\n",
            "           1       0.93      0.76      0.84        37\n",
            "\n",
            "    accuracy                           0.90       112\n",
            "   macro avg       0.91      0.87      0.88       112\n",
            "weighted avg       0.90      0.90      0.90       112\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.86 train, 0.14 test\n",
            "\n",
            "Training SVM with split 0.14...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.14: 0.9\n",
            "SVM Classification Report with split 0.14:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.97      0.93        79\n",
            "           1       0.94      0.76      0.84        41\n",
            "\n",
            "    accuracy                           0.90       120\n",
            "   macro avg       0.91      0.87      0.88       120\n",
            "weighted avg       0.90      0.90      0.90       120\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.85 train, 0.15 test\n",
            "\n",
            "Training SVM with split 0.15...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.15: 0.9069767441860465\n",
            "SVM Classification Report with split 0.15:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.98      0.93        87\n",
            "           1       0.94      0.76      0.84        42\n",
            "\n",
            "    accuracy                           0.91       129\n",
            "   macro avg       0.92      0.87      0.89       129\n",
            "weighted avg       0.91      0.91      0.90       129\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.84 train, 0.16 test\n",
            "\n",
            "Training SVM with split 0.16...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.16: 0.9051094890510949\n",
            "SVM Classification Report with split 0.16:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.98      0.93        94\n",
            "           1       0.94      0.74      0.83        43\n",
            "\n",
            "    accuracy                           0.91       137\n",
            "   macro avg       0.92      0.86      0.88       137\n",
            "weighted avg       0.91      0.91      0.90       137\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.83 train, 0.17 test\n",
            "\n",
            "Training SVM with split 0.17...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.17: 0.9041095890410958\n",
            "SVM Classification Report with split 0.17:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.98      0.93       100\n",
            "           1       0.94      0.74      0.83        46\n",
            "\n",
            "    accuracy                           0.90       146\n",
            "   macro avg       0.92      0.86      0.88       146\n",
            "weighted avg       0.91      0.90      0.90       146\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.8200000000000001 train, 0.18 test\n",
            "\n",
            "Training SVM with split 0.18...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.18: 0.9025974025974026\n",
            "SVM Classification Report with split 0.18:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.98      0.93       106\n",
            "           1       0.95      0.73      0.82        48\n",
            "\n",
            "    accuracy                           0.90       154\n",
            "   macro avg       0.92      0.86      0.88       154\n",
            "weighted avg       0.91      0.90      0.90       154\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.81 train, 0.19 test\n",
            "\n",
            "Training SVM with split 0.19...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.19: 0.9079754601226994\n",
            "SVM Classification Report with split 0.19:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.98      0.94       112\n",
            "           1       0.95      0.75      0.84        51\n",
            "\n",
            "    accuracy                           0.91       163\n",
            "   macro avg       0.92      0.86      0.89       163\n",
            "weighted avg       0.91      0.91      0.90       163\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.8 train, 0.2 test\n",
            "\n",
            "Training SVM with split 0.2...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.2: 0.9122807017543859\n",
            "SVM Classification Report with split 0.2:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94       118\n",
            "           1       0.95      0.75      0.84        53\n",
            "\n",
            "    accuracy                           0.91       171\n",
            "   macro avg       0.93      0.87      0.89       171\n",
            "weighted avg       0.92      0.91      0.91       171\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.79 train, 0.21 test\n",
            "\n",
            "Training SVM with split 0.21...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.21: 0.9166666666666666\n",
            "SVM Classification Report with split 0.21:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94       126\n",
            "           1       0.95      0.76      0.85        54\n",
            "\n",
            "    accuracy                           0.92       180\n",
            "   macro avg       0.93      0.87      0.89       180\n",
            "weighted avg       0.92      0.92      0.91       180\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.78 train, 0.22 test\n",
            "\n",
            "Training SVM with split 0.22...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.22: 0.9206349206349206\n",
            "SVM Classification Report with split 0.22:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.95       133\n",
            "           1       0.96      0.77      0.85        56\n",
            "\n",
            "    accuracy                           0.92       189\n",
            "   macro avg       0.93      0.88      0.90       189\n",
            "weighted avg       0.92      0.92      0.92       189\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.77 train, 0.23 test\n",
            "\n",
            "Training SVM with split 0.23...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.23: 0.8883248730964467\n",
            "SVM Classification Report with split 0.23:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.99      0.93       141\n",
            "           1       0.95      0.64      0.77        56\n",
            "\n",
            "    accuracy                           0.89       197\n",
            "   macro avg       0.91      0.81      0.85       197\n",
            "weighted avg       0.90      0.89      0.88       197\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.76 train, 0.24 test\n",
            "\n",
            "Training SVM with split 0.24...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.24: 0.9271844660194175\n",
            "SVM Classification Report with split 0.24:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.99      0.95       148\n",
            "           1       0.96      0.78      0.86        58\n",
            "\n",
            "    accuracy                           0.93       206\n",
            "   macro avg       0.94      0.88      0.90       206\n",
            "weighted avg       0.93      0.93      0.92       206\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.75 train, 0.25 test\n",
            "\n",
            "Training SVM with split 0.25...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.25: 0.9205607476635514\n",
            "SVM Classification Report with split 0.25:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.99      0.95       151\n",
            "           1       0.96      0.76      0.85        63\n",
            "\n",
            "    accuracy                           0.92       214\n",
            "   macro avg       0.93      0.87      0.90       214\n",
            "weighted avg       0.92      0.92      0.92       214\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.74 train, 0.26 test\n",
            "\n",
            "Training SVM with split 0.26...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.26: 0.9192825112107623\n",
            "SVM Classification Report with split 0.26:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.99      0.95       158\n",
            "           1       0.96      0.75      0.84        65\n",
            "\n",
            "    accuracy                           0.92       223\n",
            "   macro avg       0.93      0.87      0.90       223\n",
            "weighted avg       0.92      0.92      0.92       223\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.73 train, 0.27 test\n",
            "\n",
            "Training SVM with split 0.27...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.27: 0.9177489177489178\n",
            "SVM Classification Report with split 0.27:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.99      0.94       164\n",
            "           1       0.96      0.75      0.84        67\n",
            "\n",
            "    accuracy                           0.92       231\n",
            "   macro avg       0.93      0.87      0.89       231\n",
            "weighted avg       0.92      0.92      0.91       231\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.72 train, 0.28 test\n",
            "\n",
            "Training SVM with split 0.28...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.28: 0.9166666666666666\n",
            "SVM Classification Report with split 0.28:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94       171\n",
            "           1       0.96      0.74      0.84        69\n",
            "\n",
            "    accuracy                           0.92       240\n",
            "   macro avg       0.93      0.86      0.89       240\n",
            "weighted avg       0.92      0.92      0.91       240\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.71 train, 0.29 test\n",
            "\n",
            "Training SVM with split 0.29...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.29: 0.907258064516129\n",
            "SVM Classification Report with split 0.29:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94       176\n",
            "           1       0.93      0.74      0.82        72\n",
            "\n",
            "    accuracy                           0.91       248\n",
            "   macro avg       0.92      0.86      0.88       248\n",
            "weighted avg       0.91      0.91      0.90       248\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.7 train, 0.3 test\n",
            "\n",
            "Training SVM with split 0.3...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.3: 0.8871595330739299\n",
            "SVM Classification Report with split 0.3:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.98      0.93       184\n",
            "           1       0.92      0.66      0.77        73\n",
            "\n",
            "    accuracy                           0.89       257\n",
            "   macro avg       0.90      0.82      0.85       257\n",
            "weighted avg       0.89      0.89      0.88       257\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.69 train, 0.31 test\n",
            "\n",
            "Training SVM with split 0.31...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.31: 0.9060150375939849\n",
            "SVM Classification Report with split 0.31:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94       188\n",
            "           1       0.93      0.73      0.82        78\n",
            "\n",
            "    accuracy                           0.91       266\n",
            "   macro avg       0.92      0.85      0.88       266\n",
            "weighted avg       0.91      0.91      0.90       266\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.6799999999999999 train, 0.32 test\n",
            "\n",
            "Training SVM with split 0.32...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.32: 0.8832116788321168\n",
            "SVM Classification Report with split 0.32:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.98      0.92       194\n",
            "           1       0.93      0.65      0.76        80\n",
            "\n",
            "    accuracy                           0.88       274\n",
            "   macro avg       0.90      0.81      0.84       274\n",
            "weighted avg       0.89      0.88      0.88       274\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.6699999999999999 train, 0.33 test\n",
            "\n",
            "Training SVM with split 0.33...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.33: 0.911660777385159\n",
            "SVM Classification Report with split 0.33:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94       202\n",
            "           1       0.94      0.74      0.83        81\n",
            "\n",
            "    accuracy                           0.91       283\n",
            "   macro avg       0.92      0.86      0.88       283\n",
            "weighted avg       0.91      0.91      0.91       283\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.6599999999999999 train, 0.34 test\n",
            "\n",
            "Training SVM with split 0.34...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.34: 0.872852233676976\n",
            "SVM Classification Report with split 0.34:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.92       206\n",
            "           1       0.90      0.64      0.74        85\n",
            "\n",
            "    accuracy                           0.87       291\n",
            "   macro avg       0.88      0.80      0.83       291\n",
            "weighted avg       0.88      0.87      0.87       291\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.65 train, 0.35 test\n",
            "\n",
            "Training SVM with split 0.35...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.35: 0.89\n",
            "SVM Classification Report with split 0.35:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       214\n",
            "           1       0.87      0.72      0.79        86\n",
            "\n",
            "    accuracy                           0.89       300\n",
            "   macro avg       0.88      0.84      0.86       300\n",
            "weighted avg       0.89      0.89      0.89       300\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.64 train, 0.36 test\n",
            "\n",
            "Training SVM with split 0.36...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.36: 0.8798701298701299\n",
            "SVM Classification Report with split 0.36:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.95      0.92       221\n",
            "           1       0.86      0.69      0.76        87\n",
            "\n",
            "    accuracy                           0.88       308\n",
            "   macro avg       0.87      0.82      0.84       308\n",
            "weighted avg       0.88      0.88      0.88       308\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.63 train, 0.37 test\n",
            "\n",
            "Training SVM with split 0.37...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.37: 0.8832807570977917\n",
            "SVM Classification Report with split 0.37:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92       229\n",
            "           1       0.86      0.69      0.77        88\n",
            "\n",
            "    accuracy                           0.88       317\n",
            "   macro avg       0.87      0.82      0.84       317\n",
            "weighted avg       0.88      0.88      0.88       317\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.62 train, 0.38 test\n",
            "\n",
            "Training SVM with split 0.38...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.38: 0.8892307692307693\n",
            "SVM Classification Report with split 0.38:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.93       234\n",
            "           1       0.86      0.73      0.79        91\n",
            "\n",
            "    accuracy                           0.89       325\n",
            "   macro avg       0.88      0.84      0.86       325\n",
            "weighted avg       0.89      0.89      0.89       325\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.61 train, 0.39 test\n",
            "\n",
            "Training SVM with split 0.39...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.39: 0.8892215568862275\n",
            "SVM Classification Report with split 0.39:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.93       241\n",
            "           1       0.86      0.72      0.78        93\n",
            "\n",
            "    accuracy                           0.89       334\n",
            "   macro avg       0.88      0.84      0.85       334\n",
            "weighted avg       0.89      0.89      0.89       334\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.6 train, 0.4 test\n",
            "\n",
            "Training SVM with split 0.4...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.4: 0.8830409356725146\n",
            "SVM Classification Report with split 0.4:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92       247\n",
            "           1       0.86      0.69      0.77        95\n",
            "\n",
            "    accuracy                           0.88       342\n",
            "   macro avg       0.87      0.83      0.84       342\n",
            "weighted avg       0.88      0.88      0.88       342\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.5900000000000001 train, 0.41 test\n",
            "\n",
            "Training SVM with split 0.41...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.41: 0.886039886039886\n",
            "SVM Classification Report with split 0.41:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92       253\n",
            "           1       0.86      0.70      0.78        98\n",
            "\n",
            "    accuracy                           0.89       351\n",
            "   macro avg       0.88      0.83      0.85       351\n",
            "weighted avg       0.88      0.89      0.88       351\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.5800000000000001 train, 0.42 test\n",
            "\n",
            "Training SVM with split 0.42...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.42: 0.8777777777777778\n",
            "SVM Classification Report with split 0.42:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.95      0.92       260\n",
            "           1       0.83      0.70      0.76       100\n",
            "\n",
            "    accuracy                           0.88       360\n",
            "   macro avg       0.86      0.82      0.84       360\n",
            "weighted avg       0.88      0.88      0.87       360\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.5700000000000001 train, 0.43 test\n",
            "\n",
            "Training SVM with split 0.43...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.43: 0.8777173913043478\n",
            "SVM Classification Report with split 0.43:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.95      0.92       266\n",
            "           1       0.84      0.70      0.76       102\n",
            "\n",
            "    accuracy                           0.88       368\n",
            "   macro avg       0.86      0.82      0.84       368\n",
            "weighted avg       0.88      0.88      0.87       368\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.56 train, 0.44 test\n",
            "\n",
            "Training SVM with split 0.44...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.44: 0.8779840848806366\n",
            "SVM Classification Report with split 0.44:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.95      0.92       273\n",
            "           1       0.84      0.69      0.76       104\n",
            "\n",
            "    accuracy                           0.88       377\n",
            "   macro avg       0.86      0.82      0.84       377\n",
            "weighted avg       0.88      0.88      0.87       377\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.55 train, 0.45 test\n",
            "\n",
            "Training SVM with split 0.45...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.45: 0.8805194805194805\n",
            "SVM Classification Report with split 0.45:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.95      0.92       278\n",
            "           1       0.84      0.70      0.77       107\n",
            "\n",
            "    accuracy                           0.88       385\n",
            "   macro avg       0.87      0.83      0.84       385\n",
            "weighted avg       0.88      0.88      0.88       385\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.54 train, 0.46 test\n",
            "\n",
            "Training SVM with split 0.46...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.46: 0.8807106598984772\n",
            "SVM Classification Report with split 0.46:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92       283\n",
            "           1       0.86      0.68      0.76       111\n",
            "\n",
            "    accuracy                           0.88       394\n",
            "   macro avg       0.87      0.82      0.84       394\n",
            "weighted avg       0.88      0.88      0.88       394\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.53 train, 0.47 test\n",
            "\n",
            "Training SVM with split 0.47...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.47: 0.8830845771144279\n",
            "SVM Classification Report with split 0.47:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92       289\n",
            "           1       0.87      0.69      0.77       113\n",
            "\n",
            "    accuracy                           0.88       402\n",
            "   macro avg       0.88      0.82      0.85       402\n",
            "weighted avg       0.88      0.88      0.88       402\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.52 train, 0.48 test\n",
            "\n",
            "Training SVM with split 0.48...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.48: 0.8759124087591241\n",
            "SVM Classification Report with split 0.48:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92       294\n",
            "           1       0.87      0.67      0.75       117\n",
            "\n",
            "    accuracy                           0.88       411\n",
            "   macro avg       0.87      0.81      0.84       411\n",
            "weighted avg       0.88      0.88      0.87       411\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.51 train, 0.49 test\n",
            "\n",
            "Training SVM with split 0.49...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.49: 0.8663484486873508\n",
            "SVM Classification Report with split 0.49:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91       300\n",
            "           1       0.83      0.66      0.74       119\n",
            "\n",
            "    accuracy                           0.87       419\n",
            "   macro avg       0.85      0.81      0.82       419\n",
            "weighted avg       0.86      0.87      0.86       419\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.5 train, 0.5 test\n",
            "\n",
            "Training SVM with split 0.5...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.5: 0.866822429906542\n",
            "SVM Classification Report with split 0.5:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91       307\n",
            "           1       0.83      0.66      0.74       121\n",
            "\n",
            "    accuracy                           0.87       428\n",
            "   macro avg       0.85      0.80      0.82       428\n",
            "weighted avg       0.86      0.87      0.86       428\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.49 train, 0.51 test\n",
            "\n",
            "Training SVM with split 0.51...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.51: 0.8672768878718535\n",
            "SVM Classification Report with split 0.51:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91       313\n",
            "           1       0.84      0.66      0.74       124\n",
            "\n",
            "    accuracy                           0.87       437\n",
            "   macro avg       0.86      0.81      0.82       437\n",
            "weighted avg       0.86      0.87      0.86       437\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.48 train, 0.52 test\n",
            "\n",
            "Training SVM with split 0.52...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.52: 0.851685393258427\n",
            "SVM Classification Report with split 0.52:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90       320\n",
            "           1       0.82      0.60      0.69       125\n",
            "\n",
            "    accuracy                           0.85       445\n",
            "   macro avg       0.84      0.77      0.80       445\n",
            "weighted avg       0.85      0.85      0.84       445\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.47 train, 0.53 test\n",
            "\n",
            "Training SVM with split 0.53...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.53: 0.8700440528634361\n",
            "SVM Classification Report with split 0.53:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91       326\n",
            "           1       0.84      0.66      0.74       128\n",
            "\n",
            "    accuracy                           0.87       454\n",
            "   macro avg       0.86      0.81      0.83       454\n",
            "weighted avg       0.87      0.87      0.86       454\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.45999999999999996 train, 0.54 test\n",
            "\n",
            "Training SVM with split 0.54...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.54: 0.8506493506493507\n",
            "SVM Classification Report with split 0.54:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90       332\n",
            "           1       0.84      0.58      0.68       130\n",
            "\n",
            "    accuracy                           0.85       462\n",
            "   macro avg       0.85      0.77      0.79       462\n",
            "weighted avg       0.85      0.85      0.84       462\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.44999999999999996 train, 0.55 test\n",
            "\n",
            "Training SVM with split 0.55...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.55: 0.8492569002123143\n",
            "SVM Classification Report with split 0.55:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90       339\n",
            "           1       0.84      0.57      0.68       132\n",
            "\n",
            "    accuracy                           0.85       471\n",
            "   macro avg       0.85      0.76      0.79       471\n",
            "weighted avg       0.85      0.85      0.84       471\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.43999999999999995 train, 0.56 test\n",
            "\n",
            "Training SVM with split 0.56...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.56: 0.7640918580375783\n",
            "SVM Classification Report with split 0.56:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.96      0.85       344\n",
            "           1       0.71      0.27      0.40       135\n",
            "\n",
            "    accuracy                           0.76       479\n",
            "   macro avg       0.74      0.62      0.62       479\n",
            "weighted avg       0.75      0.76      0.72       479\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.43000000000000005 train, 0.57 test\n",
            "\n",
            "Training SVM with split 0.57...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.57: 0.8688524590163934\n",
            "SVM Classification Report with split 0.57:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91       350\n",
            "           1       0.85      0.65      0.74       138\n",
            "\n",
            "    accuracy                           0.87       488\n",
            "   macro avg       0.86      0.80      0.83       488\n",
            "weighted avg       0.87      0.87      0.86       488\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.42000000000000004 train, 0.58 test\n",
            "\n",
            "Training SVM with split 0.58...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.58: 0.8568548387096774\n",
            "SVM Classification Report with split 0.58:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.97      0.91       355\n",
            "           1       0.89      0.57      0.69       141\n",
            "\n",
            "    accuracy                           0.86       496\n",
            "   macro avg       0.87      0.77      0.80       496\n",
            "weighted avg       0.86      0.86      0.85       496\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.41000000000000003 train, 0.59 test\n",
            "\n",
            "Training SVM with split 0.59...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.59: 0.8435643564356435\n",
            "SVM Classification Report with split 0.59:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.98      0.90       361\n",
            "           1       0.90      0.51      0.65       144\n",
            "\n",
            "    accuracy                           0.84       505\n",
            "   macro avg       0.87      0.74      0.77       505\n",
            "weighted avg       0.85      0.84      0.83       505\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.4 train, 0.6 test\n",
            "\n",
            "Training SVM with split 0.6...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.6: 0.8304093567251462\n",
            "SVM Classification Report with split 0.6:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.96      0.89       366\n",
            "           1       0.84      0.50      0.63       147\n",
            "\n",
            "    accuracy                           0.83       513\n",
            "   macro avg       0.83      0.73      0.76       513\n",
            "weighted avg       0.83      0.83      0.82       513\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'df_encoded' is your encoded DataFrame with the target column 'CLASS'\n",
        "target_column = 'CLASS'\n",
        "\n",
        "# Split into features and target\n",
        "X = df_encoded.drop(target_column, axis=1)\n",
        "y = df_encoded[target_column]\n",
        "\n",
        "# Duplicate the data 10 times\n",
        "X_duplicated = pd.concat([X] * 5, ignore_index=True)\n",
        "y_duplicated = pd.concat([y] * 5, ignore_index=True)\n",
        "\n",
        "# Combine features and target for easier manipulation\n",
        "df_duplicated = pd.concat([X_duplicated, y_duplicated], axis=1)\n",
        "\n",
        "# Insert rows ensuring a minimum gap of 3 between duplicates\n",
        "final_data = []\n",
        "for i in range(10):  # Loop over the 10 copies\n",
        "    # Append each copy to the final list with spacing of 3 rows in between\n",
        "    gap_start = i * 3\n",
        "    final_data[gap_start:gap_start] = df_duplicated.iloc[i * len(df_encoded):(i + 1) * len(df_encoded)].values.tolist()\n",
        "\n",
        "# Convert back to DataFrame after interspersing duplicates\n",
        "df_interspersed = pd.DataFrame(final_data, columns=df_duplicated.columns)\n",
        "\n",
        "# Shuffle the final DataFrame in a highly random order\n",
        "df_shuffled = df_interspersed.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split shuffled data back into features and target\n",
        "X_shuffled = df_shuffled.drop(target_column, axis=1)\n",
        "y_shuffled = df_shuffled[target_column]\n",
        "\n",
        "# Define K-Fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Classifier and parameter grid for brute-force optimization\n",
        "classifier = SVC()\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Brute force search using GridSearchCV with KFold cross-validation and train_test_split\n",
        "train_test_splits = [\n",
        "    0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14,\n",
        "    0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24,\n",
        "    0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34,\n",
        "    0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44,\n",
        "    0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n",
        "    0.55, 0.56, 0.57, 0.58, 0.59, 0.6\n",
        "]  # Different train-test split ratios\n",
        "\n",
        "best_models = {}\n",
        "for split_ratio in train_test_splits:\n",
        "    print(f\"\\nEvaluating with train_test_split ratio: {1 - split_ratio} train, {split_ratio} test\\n\")\n",
        "\n",
        "    # Split the shuffled data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=split_ratio, random_state=42)\n",
        "\n",
        "    print(f\"Training SVM with split {split_ratio}...\")\n",
        "\n",
        "    # Brute force with GridSearchCV and KFold\n",
        "    grid_search = GridSearchCV(classifier, param_grid, cv=kf, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Evaluate the best model on the test data\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"SVM Accuracy with split {split_ratio}: {accuracy}\")\n",
        "    print(f\"SVM Classification Report with split {split_ratio}:\\n\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Store the best model for each split\n",
        "    best_models[split_ratio] = best_model\n",
        "\n",
        "# After completing all splits, the best models will be stored in `best_models`\n"
      ],
      "metadata": {
        "id": "xiV_6EV5LeGH",
        "outputId": "acc8d737-e8b0-4b7d-e4f2-50611aed5dfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating with train_test_split ratio: 0.95 train, 0.05 test\n",
            "\n",
            "Training SVM with split 0.05...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.05: 0.875\n",
            "SVM Classification Report with split 0.05:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91        48\n",
            "           1       0.83      0.79      0.81        24\n",
            "\n",
            "    accuracy                           0.88        72\n",
            "   macro avg       0.86      0.85      0.86        72\n",
            "weighted avg       0.87      0.88      0.87        72\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.94 train, 0.06 test\n",
            "\n",
            "Training SVM with split 0.06...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.06: 0.8837209302325582\n",
            "SVM Classification Report with split 0.06:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.95      0.92        60\n",
            "           1       0.86      0.73      0.79        26\n",
            "\n",
            "    accuracy                           0.88        86\n",
            "   macro avg       0.88      0.84      0.86        86\n",
            "weighted avg       0.88      0.88      0.88        86\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.9299999999999999 train, 0.07 test\n",
            "\n",
            "Training SVM with split 0.07...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.07: 0.89\n",
            "SVM Classification Report with split 0.07:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92        70\n",
            "           1       0.88      0.73      0.80        30\n",
            "\n",
            "    accuracy                           0.89       100\n",
            "   macro avg       0.89      0.85      0.86       100\n",
            "weighted avg       0.89      0.89      0.89       100\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.92 train, 0.08 test\n",
            "\n",
            "Training SVM with split 0.08...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.08: 0.9035087719298246\n",
            "SVM Classification Report with split 0.08:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93        81\n",
            "           1       0.89      0.76      0.82        33\n",
            "\n",
            "    accuracy                           0.90       114\n",
            "   macro avg       0.90      0.86      0.88       114\n",
            "weighted avg       0.90      0.90      0.90       114\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.91 train, 0.09 test\n",
            "\n",
            "Training SVM with split 0.09...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.09: 0.8837209302325582\n",
            "SVM Classification Report with split 0.09:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92        92\n",
            "           1       0.82      0.76      0.79        37\n",
            "\n",
            "    accuracy                           0.88       129\n",
            "   macro avg       0.86      0.85      0.85       129\n",
            "weighted avg       0.88      0.88      0.88       129\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.9 train, 0.1 test\n",
            "\n",
            "Training SVM with split 0.1...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.1: 0.8811188811188811\n",
            "SVM Classification Report with split 0.1:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       102\n",
            "           1       0.83      0.73      0.78        41\n",
            "\n",
            "    accuracy                           0.88       143\n",
            "   macro avg       0.87      0.84      0.85       143\n",
            "weighted avg       0.88      0.88      0.88       143\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.89 train, 0.11 test\n",
            "\n",
            "Training SVM with split 0.11...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.11: 0.8726114649681529\n",
            "SVM Classification Report with split 0.11:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91       110\n",
            "           1       0.85      0.70      0.77        47\n",
            "\n",
            "    accuracy                           0.87       157\n",
            "   macro avg       0.86      0.82      0.84       157\n",
            "weighted avg       0.87      0.87      0.87       157\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.88 train, 0.12 test\n",
            "\n",
            "Training SVM with split 0.12...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.12: 0.8771929824561403\n",
            "SVM Classification Report with split 0.12:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.92       123\n",
            "           1       0.83      0.71      0.76        48\n",
            "\n",
            "    accuracy                           0.88       171\n",
            "   macro avg       0.86      0.83      0.84       171\n",
            "weighted avg       0.87      0.88      0.87       171\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.87 train, 0.13 test\n",
            "\n",
            "Training SVM with split 0.13...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.13: 0.8602150537634409\n",
            "SVM Classification Report with split 0.13:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.90       131\n",
            "           1       0.82      0.67      0.74        55\n",
            "\n",
            "    accuracy                           0.86       186\n",
            "   macro avg       0.85      0.81      0.82       186\n",
            "weighted avg       0.86      0.86      0.86       186\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.86 train, 0.14 test\n",
            "\n",
            "Training SVM with split 0.14...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.14: 0.855\n",
            "SVM Classification Report with split 0.14:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.94      0.90       140\n",
            "           1       0.83      0.65      0.73        60\n",
            "\n",
            "    accuracy                           0.85       200\n",
            "   macro avg       0.85      0.80      0.81       200\n",
            "weighted avg       0.85      0.85      0.85       200\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.85 train, 0.15 test\n",
            "\n",
            "Training SVM with split 0.15...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.15: 0.8504672897196262\n",
            "SVM Classification Report with split 0.15:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.94      0.90       148\n",
            "           1       0.83      0.65      0.73        66\n",
            "\n",
            "    accuracy                           0.85       214\n",
            "   macro avg       0.84      0.80      0.81       214\n",
            "weighted avg       0.85      0.85      0.84       214\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.84 train, 0.16 test\n",
            "\n",
            "Training SVM with split 0.16...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.16: 0.8552631578947368\n",
            "SVM Classification Report with split 0.16:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.94      0.90       159\n",
            "           1       0.83      0.65      0.73        69\n",
            "\n",
            "    accuracy                           0.86       228\n",
            "   macro avg       0.85      0.80      0.82       228\n",
            "weighted avg       0.85      0.86      0.85       228\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.83 train, 0.17 test\n",
            "\n",
            "Training SVM with split 0.17...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.17: 0.8518518518518519\n",
            "SVM Classification Report with split 0.17:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90       167\n",
            "           1       0.84      0.64      0.73        76\n",
            "\n",
            "    accuracy                           0.85       243\n",
            "   macro avg       0.85      0.80      0.81       243\n",
            "weighted avg       0.85      0.85      0.85       243\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.8200000000000001 train, 0.18 test\n",
            "\n",
            "Training SVM with split 0.18...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.18: 0.8482490272373541\n",
            "SVM Classification Report with split 0.18:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.94      0.89       176\n",
            "           1       0.84      0.64      0.73        81\n",
            "\n",
            "    accuracy                           0.85       257\n",
            "   macro avg       0.84      0.79      0.81       257\n",
            "weighted avg       0.85      0.85      0.84       257\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.81 train, 0.19 test\n",
            "\n",
            "Training SVM with split 0.19...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.19: 0.8523985239852399\n",
            "SVM Classification Report with split 0.19:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90       185\n",
            "           1       0.85      0.65      0.74        86\n",
            "\n",
            "    accuracy                           0.85       271\n",
            "   macro avg       0.85      0.80      0.82       271\n",
            "weighted avg       0.85      0.85      0.85       271\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.8 train, 0.2 test\n",
            "\n",
            "Training SVM with split 0.2...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.2: 0.8526315789473684\n",
            "SVM Classification Report with split 0.2:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90       193\n",
            "           1       0.86      0.65      0.74        92\n",
            "\n",
            "    accuracy                           0.85       285\n",
            "   macro avg       0.85      0.80      0.82       285\n",
            "weighted avg       0.85      0.85      0.85       285\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.79 train, 0.21 test\n",
            "\n",
            "Training SVM with split 0.21...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.21: 0.85\n",
            "SVM Classification Report with split 0.21:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90       203\n",
            "           1       0.86      0.64      0.73        97\n",
            "\n",
            "    accuracy                           0.85       300\n",
            "   macro avg       0.85      0.79      0.81       300\n",
            "weighted avg       0.85      0.85      0.84       300\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.78 train, 0.22 test\n",
            "\n",
            "Training SVM with split 0.22...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.22: 0.856687898089172\n",
            "SVM Classification Report with split 0.22:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90       213\n",
            "           1       0.87      0.65      0.75       101\n",
            "\n",
            "    accuracy                           0.86       314\n",
            "   macro avg       0.86      0.80      0.82       314\n",
            "weighted avg       0.86      0.86      0.85       314\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.77 train, 0.23 test\n",
            "\n",
            "Training SVM with split 0.23...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.23: 0.8628048780487805\n",
            "SVM Classification Report with split 0.23:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.90       223\n",
            "           1       0.88      0.67      0.76       105\n",
            "\n",
            "    accuracy                           0.86       328\n",
            "   macro avg       0.87      0.81      0.83       328\n",
            "weighted avg       0.86      0.86      0.86       328\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.76 train, 0.24 test\n",
            "\n",
            "Training SVM with split 0.24...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.24: 0.8654970760233918\n",
            "SVM Classification Report with split 0.24:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.97      0.91       234\n",
            "           1       0.92      0.63      0.75       108\n",
            "\n",
            "    accuracy                           0.87       342\n",
            "   macro avg       0.88      0.80      0.83       342\n",
            "weighted avg       0.87      0.87      0.86       342\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.75 train, 0.25 test\n",
            "\n",
            "Training SVM with split 0.25...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.25: 0.8683473389355743\n",
            "SVM Classification Report with split 0.25:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.98      0.91       247\n",
            "           1       0.92      0.63      0.75       110\n",
            "\n",
            "    accuracy                           0.87       357\n",
            "   macro avg       0.89      0.80      0.83       357\n",
            "weighted avg       0.87      0.87      0.86       357\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.74 train, 0.26 test\n",
            "\n",
            "Training SVM with split 0.26...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.26: 0.8598382749326146\n",
            "SVM Classification Report with split 0.26:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90       256\n",
            "           1       0.86      0.65      0.74       115\n",
            "\n",
            "    accuracy                           0.86       371\n",
            "   macro avg       0.86      0.80      0.82       371\n",
            "weighted avg       0.86      0.86      0.85       371\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.73 train, 0.27 test\n",
            "\n",
            "Training SVM with split 0.27...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.27: 0.8623376623376623\n",
            "SVM Classification Report with split 0.27:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.91       265\n",
            "           1       0.87      0.66      0.75       120\n",
            "\n",
            "    accuracy                           0.86       385\n",
            "   macro avg       0.86      0.81      0.83       385\n",
            "weighted avg       0.86      0.86      0.86       385\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.72 train, 0.28 test\n",
            "\n",
            "Training SVM with split 0.28...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.28: 0.8575\n",
            "SVM Classification Report with split 0.28:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90       273\n",
            "           1       0.87      0.65      0.74       127\n",
            "\n",
            "    accuracy                           0.86       400\n",
            "   macro avg       0.86      0.80      0.82       400\n",
            "weighted avg       0.86      0.86      0.85       400\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.71 train, 0.29 test\n",
            "\n",
            "Training SVM with split 0.29...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.29: 0.8599033816425121\n",
            "SVM Classification Report with split 0.29:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90       284\n",
            "           1       0.87      0.65      0.75       130\n",
            "\n",
            "    accuracy                           0.86       414\n",
            "   macro avg       0.86      0.80      0.82       414\n",
            "weighted avg       0.86      0.86      0.85       414\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.7 train, 0.3 test\n",
            "\n",
            "Training SVM with split 0.3...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.3: 0.8621495327102804\n",
            "SVM Classification Report with split 0.3:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.90       294\n",
            "           1       0.87      0.66      0.75       134\n",
            "\n",
            "    accuracy                           0.86       428\n",
            "   macro avg       0.87      0.81      0.83       428\n",
            "weighted avg       0.86      0.86      0.86       428\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.69 train, 0.31 test\n",
            "\n",
            "Training SVM with split 0.31...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.31: 0.8642533936651584\n",
            "SVM Classification Report with split 0.31:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91       303\n",
            "           1       0.88      0.66      0.75       139\n",
            "\n",
            "    accuracy                           0.86       442\n",
            "   macro avg       0.87      0.81      0.83       442\n",
            "weighted avg       0.87      0.86      0.86       442\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.6799999999999999 train, 0.32 test\n",
            "\n",
            "Training SVM with split 0.32...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.32: 0.8662280701754386\n",
            "SVM Classification Report with split 0.32:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91       315\n",
            "           1       0.88      0.66      0.75       141\n",
            "\n",
            "    accuracy                           0.87       456\n",
            "   macro avg       0.87      0.81      0.83       456\n",
            "weighted avg       0.87      0.87      0.86       456\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.6699999999999999 train, 0.33 test\n",
            "\n",
            "Training SVM with split 0.33...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.33: 0.8662420382165605\n",
            "SVM Classification Report with split 0.33:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91       326\n",
            "           1       0.88      0.66      0.75       145\n",
            "\n",
            "    accuracy                           0.87       471\n",
            "   macro avg       0.87      0.81      0.83       471\n",
            "weighted avg       0.87      0.87      0.86       471\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.6599999999999999 train, 0.34 test\n",
            "\n",
            "Training SVM with split 0.34...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.34: 0.865979381443299\n",
            "SVM Classification Report with split 0.34:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.97      0.91       333\n",
            "           1       0.90      0.64      0.75       152\n",
            "\n",
            "    accuracy                           0.87       485\n",
            "   macro avg       0.88      0.81      0.83       485\n",
            "weighted avg       0.87      0.87      0.86       485\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.65 train, 0.35 test\n",
            "\n",
            "Training SVM with split 0.35...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.35: 0.8677354709418837\n",
            "SVM Classification Report with split 0.35:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.97      0.91       343\n",
            "           1       0.90      0.65      0.75       156\n",
            "\n",
            "    accuracy                           0.87       499\n",
            "   macro avg       0.88      0.81      0.83       499\n",
            "weighted avg       0.87      0.87      0.86       499\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.64 train, 0.36 test\n",
            "\n",
            "Training SVM with split 0.36...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.36: 0.8674463937621832\n",
            "SVM Classification Report with split 0.36:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.97      0.91       355\n",
            "           1       0.89      0.65      0.75       158\n",
            "\n",
            "    accuracy                           0.87       513\n",
            "   macro avg       0.88      0.81      0.83       513\n",
            "weighted avg       0.87      0.87      0.86       513\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.63 train, 0.37 test\n",
            "\n",
            "Training SVM with split 0.37...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.37: 0.8693181818181818\n",
            "SVM Classification Report with split 0.37:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.97      0.91       364\n",
            "           1       0.90      0.65      0.76       164\n",
            "\n",
            "    accuracy                           0.87       528\n",
            "   macro avg       0.88      0.81      0.83       528\n",
            "weighted avg       0.87      0.87      0.86       528\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.62 train, 0.38 test\n",
            "\n",
            "Training SVM with split 0.38...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.38: 0.8708487084870848\n",
            "SVM Classification Report with split 0.38:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.97      0.91       372\n",
            "           1       0.90      0.66      0.76       170\n",
            "\n",
            "    accuracy                           0.87       542\n",
            "   macro avg       0.88      0.81      0.84       542\n",
            "weighted avg       0.87      0.87      0.86       542\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.61 train, 0.39 test\n",
            "\n",
            "Training SVM with split 0.39...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.39: 0.8669064748201439\n",
            "SVM Classification Report with split 0.39:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.97      0.91       380\n",
            "           1       0.90      0.65      0.76       176\n",
            "\n",
            "    accuracy                           0.87       556\n",
            "   macro avg       0.88      0.81      0.83       556\n",
            "weighted avg       0.87      0.87      0.86       556\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.6 train, 0.4 test\n",
            "\n",
            "Training SVM with split 0.4...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.4: 0.8701754385964913\n",
            "SVM Classification Report with split 0.4:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.97      0.91       392\n",
            "           1       0.90      0.66      0.76       178\n",
            "\n",
            "    accuracy                           0.87       570\n",
            "   macro avg       0.88      0.81      0.84       570\n",
            "weighted avg       0.87      0.87      0.86       570\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.5900000000000001 train, 0.41 test\n",
            "\n",
            "Training SVM with split 0.41...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.41: 0.8735042735042735\n",
            "SVM Classification Report with split 0.41:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.91       404\n",
            "           1       0.90      0.66      0.76       181\n",
            "\n",
            "    accuracy                           0.87       585\n",
            "   macro avg       0.88      0.82      0.84       585\n",
            "weighted avg       0.88      0.87      0.87       585\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.5800000000000001 train, 0.42 test\n",
            "\n",
            "Training SVM with split 0.42...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.42: 0.8747913188647746\n",
            "SVM Classification Report with split 0.42:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.91       413\n",
            "           1       0.91      0.67      0.77       186\n",
            "\n",
            "    accuracy                           0.87       599\n",
            "   macro avg       0.89      0.82      0.84       599\n",
            "weighted avg       0.88      0.87      0.87       599\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.5700000000000001 train, 0.43 test\n",
            "\n",
            "Training SVM with split 0.43...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.43: 0.8743882544861338\n",
            "SVM Classification Report with split 0.43:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.91       424\n",
            "           1       0.91      0.66      0.76       189\n",
            "\n",
            "    accuracy                           0.87       613\n",
            "   macro avg       0.89      0.82      0.84       613\n",
            "weighted avg       0.88      0.87      0.87       613\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.56 train, 0.44 test\n",
            "\n",
            "Training SVM with split 0.44...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.44: 0.8755980861244019\n",
            "SVM Classification Report with split 0.44:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.92       434\n",
            "           1       0.91      0.66      0.77       193\n",
            "\n",
            "    accuracy                           0.88       627\n",
            "   macro avg       0.89      0.82      0.84       627\n",
            "weighted avg       0.88      0.88      0.87       627\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.55 train, 0.45 test\n",
            "\n",
            "Training SVM with split 0.45...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.45: 0.8738317757009346\n",
            "SVM Classification Report with split 0.45:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.97      0.91       445\n",
            "           1       0.91      0.65      0.76       197\n",
            "\n",
            "    accuracy                           0.87       642\n",
            "   macro avg       0.89      0.81      0.84       642\n",
            "weighted avg       0.88      0.87      0.87       642\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.54 train, 0.46 test\n",
            "\n",
            "Training SVM with split 0.46...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.46: 0.8734756097560976\n",
            "SVM Classification Report with split 0.46:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.97      0.91       455\n",
            "           1       0.90      0.66      0.76       201\n",
            "\n",
            "    accuracy                           0.87       656\n",
            "   macro avg       0.88      0.81      0.84       656\n",
            "weighted avg       0.88      0.87      0.87       656\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.53 train, 0.47 test\n",
            "\n",
            "Training SVM with split 0.47...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.47: 0.8731343283582089\n",
            "SVM Classification Report with split 0.47:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.91       465\n",
            "           1       0.90      0.66      0.76       205\n",
            "\n",
            "    accuracy                           0.87       670\n",
            "   macro avg       0.88      0.81      0.84       670\n",
            "weighted avg       0.88      0.87      0.87       670\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.52 train, 0.48 test\n",
            "\n",
            "Training SVM with split 0.48...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.48: 0.868421052631579\n",
            "SVM Classification Report with split 0.48:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91       477\n",
            "           1       0.87      0.66      0.75       207\n",
            "\n",
            "    accuracy                           0.87       684\n",
            "   macro avg       0.87      0.81      0.83       684\n",
            "weighted avg       0.87      0.87      0.86       684\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.51 train, 0.49 test\n",
            "\n",
            "Training SVM with split 0.49...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.49: 0.8640915593705293\n",
            "SVM Classification Report with split 0.49:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91       489\n",
            "           1       0.87      0.64      0.74       210\n",
            "\n",
            "    accuracy                           0.86       699\n",
            "   macro avg       0.87      0.80      0.82       699\n",
            "weighted avg       0.86      0.86      0.86       699\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.5 train, 0.5 test\n",
            "\n",
            "Training SVM with split 0.5...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.5: 0.8625525946704067\n",
            "SVM Classification Report with split 0.5:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91       498\n",
            "           1       0.87      0.64      0.74       215\n",
            "\n",
            "    accuracy                           0.86       713\n",
            "   macro avg       0.87      0.80      0.82       713\n",
            "weighted avg       0.86      0.86      0.86       713\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.49 train, 0.51 test\n",
            "\n",
            "Training SVM with split 0.51...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.51: 0.8720770288858322\n",
            "SVM Classification Report with split 0.51:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91       510\n",
            "           1       0.88      0.66      0.76       217\n",
            "\n",
            "    accuracy                           0.87       727\n",
            "   macro avg       0.87      0.81      0.83       727\n",
            "weighted avg       0.87      0.87      0.87       727\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.48 train, 0.52 test\n",
            "\n",
            "Training SVM with split 0.52...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.52: 0.8677462887989204\n",
            "SVM Classification Report with split 0.52:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91       520\n",
            "           1       0.88      0.65      0.74       221\n",
            "\n",
            "    accuracy                           0.87       741\n",
            "   macro avg       0.87      0.80      0.83       741\n",
            "weighted avg       0.87      0.87      0.86       741\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.47 train, 0.53 test\n",
            "\n",
            "Training SVM with split 0.53...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.53: 0.8703703703703703\n",
            "SVM Classification Report with split 0.53:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91       533\n",
            "           1       0.88      0.65      0.75       223\n",
            "\n",
            "    accuracy                           0.87       756\n",
            "   macro avg       0.87      0.81      0.83       756\n",
            "weighted avg       0.87      0.87      0.86       756\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.45999999999999996 train, 0.54 test\n",
            "\n",
            "Training SVM with split 0.54...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.54: 0.8727272727272727\n",
            "SVM Classification Report with split 0.54:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91       544\n",
            "           1       0.88      0.65      0.75       226\n",
            "\n",
            "    accuracy                           0.87       770\n",
            "   macro avg       0.88      0.81      0.83       770\n",
            "weighted avg       0.87      0.87      0.87       770\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.44999999999999996 train, 0.55 test\n",
            "\n",
            "Training SVM with split 0.55...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.55: 0.8635204081632653\n",
            "SVM Classification Report with split 0.55:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91       554\n",
            "           1       0.86      0.64      0.73       230\n",
            "\n",
            "    accuracy                           0.86       784\n",
            "   macro avg       0.86      0.80      0.82       784\n",
            "weighted avg       0.86      0.86      0.86       784\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.43999999999999995 train, 0.56 test\n",
            "\n",
            "Training SVM with split 0.56...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.56: 0.8648310387984981\n",
            "SVM Classification Report with split 0.56:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91       565\n",
            "           1       0.86      0.65      0.74       234\n",
            "\n",
            "    accuracy                           0.86       799\n",
            "   macro avg       0.86      0.80      0.82       799\n",
            "weighted avg       0.86      0.86      0.86       799\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.43000000000000005 train, 0.57 test\n",
            "\n",
            "Training SVM with split 0.57...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.57: 0.8671586715867159\n",
            "SVM Classification Report with split 0.57:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91       576\n",
            "           1       0.86      0.65      0.74       237\n",
            "\n",
            "    accuracy                           0.87       813\n",
            "   macro avg       0.86      0.80      0.83       813\n",
            "weighted avg       0.87      0.87      0.86       813\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.42000000000000004 train, 0.58 test\n",
            "\n",
            "Training SVM with split 0.58...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.58: 0.8669891172914147\n",
            "SVM Classification Report with split 0.58:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91       587\n",
            "           1       0.86      0.65      0.74       240\n",
            "\n",
            "    accuracy                           0.87       827\n",
            "   macro avg       0.86      0.80      0.82       827\n",
            "weighted avg       0.87      0.87      0.86       827\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.41000000000000003 train, 0.59 test\n",
            "\n",
            "Training SVM with split 0.59...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.59: 0.8668252080856124\n",
            "SVM Classification Report with split 0.59:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91       599\n",
            "           1       0.86      0.64      0.74       242\n",
            "\n",
            "    accuracy                           0.87       841\n",
            "   macro avg       0.86      0.80      0.82       841\n",
            "weighted avg       0.87      0.87      0.86       841\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.4 train, 0.6 test\n",
            "\n",
            "Training SVM with split 0.6...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.6: 0.8619883040935673\n",
            "SVM Classification Report with split 0.6:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91       610\n",
            "           1       0.85      0.62      0.72       245\n",
            "\n",
            "    accuracy                           0.86       855\n",
            "   macro avg       0.86      0.79      0.81       855\n",
            "weighted avg       0.86      0.86      0.85       855\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'df_encoded' is your encoded DataFrame with the target column 'CLASS'\n",
        "target_column = 'CLASS'\n",
        "\n",
        "# Split into features and target\n",
        "X = df_encoded.drop(target_column, axis=1)\n",
        "y = df_encoded[target_column]\n",
        "\n",
        "# Duplicate the data 10 times\n",
        "X_duplicated = pd.concat([X] * 10, ignore_index=True)\n",
        "y_duplicated = pd.concat([y] * 10, ignore_index=True)\n",
        "\n",
        "# Combine features and target for easier manipulation\n",
        "df_duplicated = pd.concat([X_duplicated, y_duplicated], axis=1)\n",
        "\n",
        "# Initialize an empty list for storing the interspersed data\n",
        "final_data = []\n",
        "\n",
        "# Insert rows ensuring a fixed gap of 5 between duplicates\n",
        "for i in range(len(df_encoded)):\n",
        "    for j in range(10):  # Loop over the 10 copies\n",
        "        final_data.append(df_duplicated.iloc[i + j * len(df_encoded)].values.tolist())\n",
        "        if j < 9:  # Add 5 \"None\" rows as gaps between duplicates except after the last one\n",
        "            final_data.extend([[None] * df_duplicated.shape[1]] * 5)\n",
        "\n",
        "# Convert back to DataFrame after interspersing duplicates\n",
        "df_interspersed = pd.DataFrame(final_data, columns=df_duplicated.columns)\n",
        "\n",
        "# Drop the rows filled with None (these are the gap rows)\n",
        "df_interspersed.dropna(inplace=True)\n",
        "\n",
        "# Shuffle the final DataFrame in a highly random order\n",
        "df_shuffled = df_interspersed.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split shuffled data back into features and target\n",
        "X_shuffled = df_shuffled.drop(target_column, axis=1)\n",
        "y_shuffled = df_shuffled[target_column]\n",
        "\n",
        "# Define K-Fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Classifier and parameter grid for brute-force optimization\n",
        "classifier = SVC()\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Brute force search using GridSearchCV with KFold cross-validation and train_test_split\n",
        "train_test_splits = [\n",
        "    0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14,\n",
        "    0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24,\n",
        "    0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34,\n",
        "    0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44,\n",
        "    0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n",
        "    0.55, 0.56, 0.57, 0.58, 0.59, 0.6\n",
        "]  # Different train-test split ratios\n",
        "\n",
        "best_models = {}\n",
        "for split_ratio in train_test_splits:\n",
        "    print(f\"\\nEvaluating with train_test_split ratio: {1 - split_ratio} train, {split_ratio} test\\n\")\n",
        "\n",
        "    # Split the shuffled data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=split_ratio, random_state=42)\n",
        "\n",
        "    print(f\"Training SVM with split {split_ratio}...\")\n",
        "\n",
        "    # Brute force with GridSearchCV and KFold\n",
        "    grid_search = GridSearchCV(classifier, param_grid, cv=kf, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Evaluate the best model on the test data\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"SVM Accuracy with split {split_ratio}: {accuracy}\")\n",
        "    print(f\"SVM Classification Report with split {split_ratio}:\\n\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Store the best model for each split\n",
        "    best_models[split_ratio] = best_model\n",
        "\n",
        "# After completing all splits, the best models will be stored in `best_models`\n"
      ],
      "metadata": {
        "id": "TtG5ffeyQBbR",
        "outputId": "1ccdd8d9-5b9f-4945-e928-a62327ccc4e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating with train_test_split ratio: 0.95 train, 0.05 test\n",
            "\n",
            "Training SVM with split 0.05...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.05: 0.8461538461538461\n",
            "SVM Classification Report with split 0.05:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.93      0.89       100\n",
            "         1.0       0.80      0.65      0.72        43\n",
            "\n",
            "    accuracy                           0.85       143\n",
            "   macro avg       0.83      0.79      0.81       143\n",
            "weighted avg       0.84      0.85      0.84       143\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.94 train, 0.06 test\n",
            "\n",
            "Training SVM with split 0.06...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.06: 0.8596491228070176\n",
            "SVM Classification Report with split 0.06:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.94      0.91       123\n",
            "         1.0       0.82      0.65      0.72        48\n",
            "\n",
            "    accuracy                           0.86       171\n",
            "   macro avg       0.84      0.79      0.81       171\n",
            "weighted avg       0.86      0.86      0.85       171\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.9299999999999999 train, 0.07 test\n",
            "\n",
            "Training SVM with split 0.07...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.07: 0.87\n",
            "SVM Classification Report with split 0.07:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.95      0.91       143\n",
            "         1.0       0.84      0.67      0.75        57\n",
            "\n",
            "    accuracy                           0.87       200\n",
            "   macro avg       0.86      0.81      0.83       200\n",
            "weighted avg       0.87      0.87      0.86       200\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.92 train, 0.08 test\n",
            "\n",
            "Training SVM with split 0.08...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.08: 0.8728070175438597\n",
            "SVM Classification Report with split 0.08:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.94      0.91       161\n",
            "         1.0       0.84      0.70      0.76        67\n",
            "\n",
            "    accuracy                           0.87       228\n",
            "   macro avg       0.86      0.82      0.84       228\n",
            "weighted avg       0.87      0.87      0.87       228\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.91 train, 0.09 test\n",
            "\n",
            "Training SVM with split 0.09...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.09: 0.8715953307392996\n",
            "SVM Classification Report with split 0.09:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.95      0.91       185\n",
            "         1.0       0.83      0.68      0.75        72\n",
            "\n",
            "    accuracy                           0.87       257\n",
            "   macro avg       0.86      0.81      0.83       257\n",
            "weighted avg       0.87      0.87      0.87       257\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.9 train, 0.1 test\n",
            "\n",
            "Training SVM with split 0.1...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.1: 0.8666666666666667\n",
            "SVM Classification Report with split 0.1:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.94      0.91       203\n",
            "         1.0       0.81      0.70      0.75        82\n",
            "\n",
            "    accuracy                           0.87       285\n",
            "   macro avg       0.85      0.82      0.83       285\n",
            "weighted avg       0.86      0.87      0.86       285\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.89 train, 0.11 test\n",
            "\n",
            "Training SVM with split 0.11...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.11: 0.8694267515923567\n",
            "SVM Classification Report with split 0.11:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.94      0.91       223\n",
            "         1.0       0.82      0.70      0.76        91\n",
            "\n",
            "    accuracy                           0.87       314\n",
            "   macro avg       0.85      0.82      0.83       314\n",
            "weighted avg       0.87      0.87      0.87       314\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.88 train, 0.12 test\n",
            "\n",
            "Training SVM with split 0.12...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.12: 0.8771929824561403\n",
            "SVM Classification Report with split 0.12:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.94      0.92       245\n",
            "         1.0       0.83      0.71      0.77        97\n",
            "\n",
            "    accuracy                           0.88       342\n",
            "   macro avg       0.86      0.83      0.84       342\n",
            "weighted avg       0.87      0.88      0.87       342\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.87 train, 0.13 test\n",
            "\n",
            "Training SVM with split 0.13...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.13: 0.8840970350404312\n",
            "SVM Classification Report with split 0.13:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.94      0.92       270\n",
            "         1.0       0.83      0.72      0.77       101\n",
            "\n",
            "    accuracy                           0.88       371\n",
            "   macro avg       0.87      0.83      0.85       371\n",
            "weighted avg       0.88      0.88      0.88       371\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.86 train, 0.14 test\n",
            "\n",
            "Training SVM with split 0.14...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.14: 0.885\n",
            "SVM Classification Report with split 0.14:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.97      0.92       290\n",
            "         1.0       0.88      0.67      0.76       110\n",
            "\n",
            "    accuracy                           0.89       400\n",
            "   macro avg       0.88      0.82      0.84       400\n",
            "weighted avg       0.88      0.89      0.88       400\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.85 train, 0.15 test\n",
            "\n",
            "Training SVM with split 0.15...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.15: 0.8785046728971962\n",
            "SVM Classification Report with split 0.15:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.97      0.92       308\n",
            "         1.0       0.89      0.65      0.75       120\n",
            "\n",
            "    accuracy                           0.88       428\n",
            "   macro avg       0.88      0.81      0.83       428\n",
            "weighted avg       0.88      0.88      0.87       428\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.84 train, 0.16 test\n",
            "\n",
            "Training SVM with split 0.16...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.16: 0.8837719298245614\n",
            "SVM Classification Report with split 0.16:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.97      0.92       329\n",
            "         1.0       0.89      0.66      0.76       127\n",
            "\n",
            "    accuracy                           0.88       456\n",
            "   macro avg       0.89      0.82      0.84       456\n",
            "weighted avg       0.88      0.88      0.88       456\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.83 train, 0.17 test\n",
            "\n",
            "Training SVM with split 0.17...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.17: 0.8783505154639175\n",
            "SVM Classification Report with split 0.17:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.95      0.92       346\n",
            "         1.0       0.86      0.69      0.76       139\n",
            "\n",
            "    accuracy                           0.88       485\n",
            "   macro avg       0.87      0.82      0.84       485\n",
            "weighted avg       0.88      0.88      0.87       485\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.8200000000000001 train, 0.18 test\n",
            "\n",
            "Training SVM with split 0.18...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.18: 0.8830409356725146\n",
            "SVM Classification Report with split 0.18:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.96      0.92       364\n",
            "         1.0       0.87      0.70      0.78       149\n",
            "\n",
            "    accuracy                           0.88       513\n",
            "   macro avg       0.88      0.83      0.85       513\n",
            "weighted avg       0.88      0.88      0.88       513\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.81 train, 0.19 test\n",
            "\n",
            "Training SVM with split 0.19...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.19: 0.8874538745387454\n",
            "SVM Classification Report with split 0.19:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.95      0.92       384\n",
            "         1.0       0.86      0.73      0.79       158\n",
            "\n",
            "    accuracy                           0.89       542\n",
            "   macro avg       0.88      0.84      0.86       542\n",
            "weighted avg       0.89      0.89      0.88       542\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.8 train, 0.2 test\n",
            "\n",
            "Training SVM with split 0.2...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.2: 0.8912280701754386\n",
            "SVM Classification Report with split 0.2:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.95      0.93       406\n",
            "         1.0       0.86      0.74      0.80       164\n",
            "\n",
            "    accuracy                           0.89       570\n",
            "   macro avg       0.88      0.85      0.86       570\n",
            "weighted avg       0.89      0.89      0.89       570\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.79 train, 0.21 test\n",
            "\n",
            "Training SVM with split 0.21...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.21: 0.8881469115191987\n",
            "SVM Classification Report with split 0.21:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.95      0.92       427\n",
            "         1.0       0.86      0.73      0.79       172\n",
            "\n",
            "    accuracy                           0.89       599\n",
            "   macro avg       0.88      0.84      0.86       599\n",
            "weighted avg       0.89      0.89      0.89       599\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.78 train, 0.22 test\n",
            "\n",
            "Training SVM with split 0.22...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.22: 0.886762360446571\n",
            "SVM Classification Report with split 0.22:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.95      0.92       444\n",
            "         1.0       0.86      0.73      0.79       183\n",
            "\n",
            "    accuracy                           0.89       627\n",
            "   macro avg       0.88      0.84      0.86       627\n",
            "weighted avg       0.89      0.89      0.88       627\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.77 train, 0.23 test\n",
            "\n",
            "Training SVM with split 0.23...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.23: 0.885670731707317\n",
            "SVM Classification Report with split 0.23:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.94      0.92       467\n",
            "         1.0       0.84      0.74      0.79       189\n",
            "\n",
            "    accuracy                           0.89       656\n",
            "   macro avg       0.87      0.84      0.86       656\n",
            "weighted avg       0.88      0.89      0.88       656\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.76 train, 0.24 test\n",
            "\n",
            "Training SVM with split 0.24...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.24: 0.8874269005847953\n",
            "SVM Classification Report with split 0.24:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.95      0.92       487\n",
            "         1.0       0.85      0.74      0.79       197\n",
            "\n",
            "    accuracy                           0.89       684\n",
            "   macro avg       0.87      0.84      0.86       684\n",
            "weighted avg       0.89      0.89      0.89       684\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.75 train, 0.25 test\n",
            "\n",
            "Training SVM with split 0.25...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.25: 0.8906030855539971\n",
            "SVM Classification Report with split 0.25:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.95      0.93       507\n",
            "         1.0       0.86      0.75      0.80       206\n",
            "\n",
            "    accuracy                           0.89       713\n",
            "   macro avg       0.88      0.85      0.86       713\n",
            "weighted avg       0.89      0.89      0.89       713\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.74 train, 0.26 test\n",
            "\n",
            "Training SVM with split 0.26...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.26: 0.8920377867746289\n",
            "SVM Classification Report with split 0.26:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.95      0.93       527\n",
            "         1.0       0.86      0.75      0.80       214\n",
            "\n",
            "    accuracy                           0.89       741\n",
            "   macro avg       0.88      0.85      0.86       741\n",
            "weighted avg       0.89      0.89      0.89       741\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.73 train, 0.27 test\n",
            "\n",
            "Training SVM with split 0.27...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.27: 0.8909090909090909\n",
            "SVM Classification Report with split 0.27:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.95      0.93       546\n",
            "         1.0       0.86      0.74      0.80       224\n",
            "\n",
            "    accuracy                           0.89       770\n",
            "   macro avg       0.88      0.85      0.86       770\n",
            "weighted avg       0.89      0.89      0.89       770\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.72 train, 0.28 test\n",
            "\n",
            "Training SVM with split 0.28...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.28: 0.8923654568210263\n",
            "SVM Classification Report with split 0.28:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.95      0.93       565\n",
            "         1.0       0.87      0.75      0.80       234\n",
            "\n",
            "    accuracy                           0.89       799\n",
            "   macro avg       0.88      0.85      0.86       799\n",
            "weighted avg       0.89      0.89      0.89       799\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.71 train, 0.29 test\n",
            "\n",
            "Training SVM with split 0.29...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.29: 0.8948004836759371\n",
            "SVM Classification Report with split 0.29:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.96      0.93       584\n",
            "         1.0       0.89      0.73      0.80       243\n",
            "\n",
            "    accuracy                           0.89       827\n",
            "   macro avg       0.89      0.85      0.87       827\n",
            "weighted avg       0.89      0.89      0.89       827\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.7 train, 0.3 test\n",
            "\n",
            "Training SVM with split 0.3...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.3: 0.8947368421052632\n",
            "SVM Classification Report with split 0.3:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.97      0.93       606\n",
            "         1.0       0.90      0.72      0.80       249\n",
            "\n",
            "    accuracy                           0.89       855\n",
            "   macro avg       0.90      0.84      0.86       855\n",
            "weighted avg       0.89      0.89      0.89       855\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.69 train, 0.31 test\n",
            "\n",
            "Training SVM with split 0.31...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.31: 0.8925339366515838\n",
            "SVM Classification Report with split 0.31:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.96      0.93       628\n",
            "         1.0       0.89      0.72      0.79       256\n",
            "\n",
            "    accuracy                           0.89       884\n",
            "   macro avg       0.89      0.84      0.86       884\n",
            "weighted avg       0.89      0.89      0.89       884\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.6799999999999999 train, 0.32 test\n",
            "\n",
            "Training SVM with split 0.32...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.32: 0.8947368421052632\n",
            "SVM Classification Report with split 0.32:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.96      0.93       648\n",
            "         1.0       0.89      0.72      0.80       264\n",
            "\n",
            "    accuracy                           0.89       912\n",
            "   macro avg       0.89      0.84      0.86       912\n",
            "weighted avg       0.89      0.89      0.89       912\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.6699999999999999 train, 0.33 test\n",
            "\n",
            "Training SVM with split 0.33...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.33: 0.8926673751328374\n",
            "SVM Classification Report with split 0.33:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.96      0.93       669\n",
            "         1.0       0.89      0.72      0.79       272\n",
            "\n",
            "    accuracy                           0.89       941\n",
            "   macro avg       0.89      0.84      0.86       941\n",
            "weighted avg       0.89      0.89      0.89       941\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.6599999999999999 train, 0.34 test\n",
            "\n",
            "Training SVM with split 0.34...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.34: 0.8917525773195877\n",
            "SVM Classification Report with split 0.34:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.97      0.93       689\n",
            "         1.0       0.89      0.71      0.79       281\n",
            "\n",
            "    accuracy                           0.89       970\n",
            "   macro avg       0.89      0.84      0.86       970\n",
            "weighted avg       0.89      0.89      0.89       970\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.65 train, 0.35 test\n",
            "\n",
            "Training SVM with split 0.35...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.35: 0.8947895791583166\n",
            "SVM Classification Report with split 0.35:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.97      0.93       712\n",
            "         1.0       0.90      0.72      0.80       286\n",
            "\n",
            "    accuracy                           0.89       998\n",
            "   macro avg       0.89      0.84      0.86       998\n",
            "weighted avg       0.89      0.89      0.89       998\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.64 train, 0.36 test\n",
            "\n",
            "Training SVM with split 0.36...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.36: 0.8957115009746589\n",
            "SVM Classification Report with split 0.36:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.97      0.93       731\n",
            "         1.0       0.90      0.72      0.80       295\n",
            "\n",
            "    accuracy                           0.90      1026\n",
            "   macro avg       0.90      0.84      0.86      1026\n",
            "weighted avg       0.90      0.90      0.89      1026\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.63 train, 0.37 test\n",
            "\n",
            "Training SVM with split 0.37...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.37: 0.8947867298578199\n",
            "SVM Classification Report with split 0.37:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.97      0.93       754\n",
            "         1.0       0.90      0.71      0.79       301\n",
            "\n",
            "    accuracy                           0.89      1055\n",
            "   macro avg       0.90      0.84      0.86      1055\n",
            "weighted avg       0.89      0.89      0.89      1055\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.62 train, 0.38 test\n",
            "\n",
            "Training SVM with split 0.38...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.38: 0.8947368421052632\n",
            "SVM Classification Report with split 0.38:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.97      0.93       776\n",
            "         1.0       0.89      0.71      0.79       307\n",
            "\n",
            "    accuracy                           0.89      1083\n",
            "   macro avg       0.89      0.84      0.86      1083\n",
            "weighted avg       0.89      0.89      0.89      1083\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.61 train, 0.39 test\n",
            "\n",
            "Training SVM with split 0.39...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.39: 0.8902877697841727\n",
            "SVM Classification Report with split 0.39:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93       795\n",
            "         1.0       0.93      0.67      0.78       317\n",
            "\n",
            "    accuracy                           0.89      1112\n",
            "   macro avg       0.90      0.82      0.85      1112\n",
            "weighted avg       0.89      0.89      0.88      1112\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.6 train, 0.4 test\n",
            "\n",
            "Training SVM with split 0.4...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.4: 0.8921052631578947\n",
            "SVM Classification Report with split 0.4:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93       817\n",
            "         1.0       0.93      0.67      0.78       323\n",
            "\n",
            "    accuracy                           0.89      1140\n",
            "   macro avg       0.91      0.83      0.85      1140\n",
            "weighted avg       0.90      0.89      0.89      1140\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.5900000000000001 train, 0.41 test\n",
            "\n",
            "Training SVM with split 0.41...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.41: 0.8922155688622755\n",
            "SVM Classification Report with split 0.41:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93       836\n",
            "         1.0       0.93      0.67      0.78       333\n",
            "\n",
            "    accuracy                           0.89      1169\n",
            "   macro avg       0.91      0.83      0.85      1169\n",
            "weighted avg       0.90      0.89      0.89      1169\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.5800000000000001 train, 0.42 test\n",
            "\n",
            "Training SVM with split 0.42...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.42: 0.8939014202172096\n",
            "SVM Classification Report with split 0.42:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93       858\n",
            "         1.0       0.93      0.68      0.78       339\n",
            "\n",
            "    accuracy                           0.89      1197\n",
            "   macro avg       0.91      0.83      0.86      1197\n",
            "weighted avg       0.90      0.89      0.89      1197\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.5700000000000001 train, 0.43 test\n",
            "\n",
            "Training SVM with split 0.43...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.43: 0.8931484502446982\n",
            "SVM Classification Report with split 0.43:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93       879\n",
            "         1.0       0.93      0.67      0.78       347\n",
            "\n",
            "    accuracy                           0.89      1226\n",
            "   macro avg       0.91      0.83      0.85      1226\n",
            "weighted avg       0.90      0.89      0.89      1226\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.56 train, 0.44 test\n",
            "\n",
            "Training SVM with split 0.44...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.44: 0.8931419457735247\n",
            "SVM Classification Report with split 0.44:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93       899\n",
            "         1.0       0.93      0.67      0.78       355\n",
            "\n",
            "    accuracy                           0.89      1254\n",
            "   macro avg       0.91      0.83      0.85      1254\n",
            "weighted avg       0.90      0.89      0.89      1254\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.55 train, 0.45 test\n",
            "\n",
            "Training SVM with split 0.45...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.45: 0.8939984411535464\n",
            "SVM Classification Report with split 0.45:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93       923\n",
            "         1.0       0.93      0.67      0.78       360\n",
            "\n",
            "    accuracy                           0.89      1283\n",
            "   macro avg       0.91      0.83      0.86      1283\n",
            "weighted avg       0.90      0.89      0.89      1283\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.54 train, 0.46 test\n",
            "\n",
            "Training SVM with split 0.46...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.46: 0.8947368421052632\n",
            "SVM Classification Report with split 0.46:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93       945\n",
            "         1.0       0.94      0.67      0.78       366\n",
            "\n",
            "    accuracy                           0.89      1311\n",
            "   macro avg       0.91      0.83      0.86      1311\n",
            "weighted avg       0.90      0.89      0.89      1311\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.53 train, 0.47 test\n",
            "\n",
            "Training SVM with split 0.47...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.47: 0.8955223880597015\n",
            "SVM Classification Report with split 0.47:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.98      0.93       968\n",
            "         1.0       0.94      0.67      0.78       372\n",
            "\n",
            "    accuracy                           0.90      1340\n",
            "   macro avg       0.91      0.83      0.86      1340\n",
            "weighted avg       0.90      0.90      0.89      1340\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.52 train, 0.48 test\n",
            "\n",
            "Training SVM with split 0.48...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.48: 0.8976608187134503\n",
            "SVM Classification Report with split 0.48:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.98      0.93       993\n",
            "         1.0       0.94      0.67      0.78       375\n",
            "\n",
            "    accuracy                           0.90      1368\n",
            "   macro avg       0.91      0.83      0.86      1368\n",
            "weighted avg       0.90      0.90      0.89      1368\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.51 train, 0.49 test\n",
            "\n",
            "Training SVM with split 0.49...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.49: 0.898353614889048\n",
            "SVM Classification Report with split 0.49:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.98      0.93      1009\n",
            "         1.0       0.94      0.68      0.79       388\n",
            "\n",
            "    accuracy                           0.90      1397\n",
            "   macro avg       0.91      0.83      0.86      1397\n",
            "weighted avg       0.90      0.90      0.89      1397\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.5 train, 0.5 test\n",
            "\n",
            "Training SVM with split 0.5...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.5: 0.8968421052631579\n",
            "SVM Classification Report with split 0.5:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.98      0.93      1027\n",
            "         1.0       0.94      0.68      0.79       398\n",
            "\n",
            "    accuracy                           0.90      1425\n",
            "   macro avg       0.91      0.83      0.86      1425\n",
            "weighted avg       0.90      0.90      0.89      1425\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.49 train, 0.51 test\n",
            "\n",
            "Training SVM with split 0.51...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.51: 0.8947730398899587\n",
            "SVM Classification Report with split 0.51:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93      1042\n",
            "         1.0       0.94      0.67      0.78       412\n",
            "\n",
            "    accuracy                           0.89      1454\n",
            "   macro avg       0.91      0.83      0.86      1454\n",
            "weighted avg       0.90      0.89      0.89      1454\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.48 train, 0.52 test\n",
            "\n",
            "Training SVM with split 0.52...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.52: 0.8927125506072875\n",
            "SVM Classification Report with split 0.52:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93      1060\n",
            "         1.0       0.94      0.67      0.78       422\n",
            "\n",
            "    accuracy                           0.89      1482\n",
            "   macro avg       0.91      0.82      0.85      1482\n",
            "weighted avg       0.90      0.89      0.89      1482\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.47 train, 0.53 test\n",
            "\n",
            "Training SVM with split 0.53...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.53: 0.8941098610191925\n",
            "SVM Classification Report with split 0.53:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93      1080\n",
            "         1.0       0.94      0.67      0.78       431\n",
            "\n",
            "    accuracy                           0.89      1511\n",
            "   macro avg       0.91      0.83      0.86      1511\n",
            "weighted avg       0.90      0.89      0.89      1511\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.45999999999999996 train, 0.54 test\n",
            "\n",
            "Training SVM with split 0.54...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.54: 0.8934372969460689\n",
            "SVM Classification Report with split 0.54:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93      1102\n",
            "         1.0       0.94      0.67      0.78       437\n",
            "\n",
            "    accuracy                           0.89      1539\n",
            "   macro avg       0.91      0.83      0.86      1539\n",
            "weighted avg       0.90      0.89      0.89      1539\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.44999999999999996 train, 0.55 test\n",
            "\n",
            "Training SVM with split 0.55...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.55: 0.892219387755102\n",
            "SVM Classification Report with split 0.55:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93      1121\n",
            "         1.0       0.94      0.67      0.78       447\n",
            "\n",
            "    accuracy                           0.89      1568\n",
            "   macro avg       0.91      0.82      0.85      1568\n",
            "weighted avg       0.90      0.89      0.89      1568\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.43999999999999995 train, 0.56 test\n",
            "\n",
            "Training SVM with split 0.56...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.56: 0.878522229179712\n",
            "SVM Classification Report with split 0.56:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.98      0.92      1140\n",
            "         1.0       0.93      0.62      0.75       457\n",
            "\n",
            "    accuracy                           0.88      1597\n",
            "   macro avg       0.90      0.80      0.83      1597\n",
            "weighted avg       0.88      0.88      0.87      1597\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.43000000000000005 train, 0.57 test\n",
            "\n",
            "Training SVM with split 0.57...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.57: 0.8849230769230769\n",
            "SVM Classification Report with split 0.57:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.99      0.92      1162\n",
            "         1.0       0.96      0.62      0.75       463\n",
            "\n",
            "    accuracy                           0.88      1625\n",
            "   macro avg       0.91      0.81      0.84      1625\n",
            "weighted avg       0.89      0.88      0.88      1625\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.42000000000000004 train, 0.58 test\n",
            "\n",
            "Training SVM with split 0.58...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.58: 0.8850574712643678\n",
            "SVM Classification Report with split 0.58:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.99      0.92      1184\n",
            "         1.0       0.96      0.62      0.75       469\n",
            "\n",
            "    accuracy                           0.89      1653\n",
            "   macro avg       0.91      0.81      0.84      1653\n",
            "weighted avg       0.89      0.89      0.88      1653\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.41000000000000003 train, 0.59 test\n",
            "\n",
            "Training SVM with split 0.59...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.59: 0.8864447086801427\n",
            "SVM Classification Report with split 0.59:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.93      1209\n",
            "         1.0       0.92      0.66      0.76       473\n",
            "\n",
            "    accuracy                           0.89      1682\n",
            "   macro avg       0.90      0.82      0.84      1682\n",
            "weighted avg       0.89      0.89      0.88      1682\n",
            "\n",
            "\n",
            "Evaluating with train_test_split ratio: 0.4 train, 0.6 test\n",
            "\n",
            "Training SVM with split 0.6...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "SVM Accuracy with split 0.6: 0.8859649122807017\n",
            "SVM Classification Report with split 0.6:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.98      0.92      1228\n",
            "         1.0       0.92      0.66      0.76       482\n",
            "\n",
            "    accuracy                           0.89      1710\n",
            "   macro avg       0.90      0.82      0.84      1710\n",
            "weighted avg       0.89      0.89      0.88      1710\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qq2cQ1FKTNcX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}